{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model and Evaluation\n",
    "\n",
    "\n",
    "## Objectives\n",
    "\n",
    "\n",
    "- Implement ML pipeline. \n",
    "- Implement regression model to predict the sale price of properties,\n",
    "\n",
    "\n",
    "## Inputs \n",
    "\n",
    "\n",
    "- outputs/datasets/datacollection/HousePrices.csv\n",
    "\n",
    "\n",
    "## Outputs\n",
    "\n",
    "\n",
    "- Train Set and Test Set. \n",
    "- Machine Learning pipeline. \n",
    "\n",
    "\n",
    "## CRISP-DM\n",
    "\n",
    "\n",
    "- \"Modelling and Evaluation\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "current_dir = os.getcwd()\n",
    "current_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(os.path.dirname(current_dir))\n",
    "print(\"You set a new current directory\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_dir = os.getcwd()\n",
    "current_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "df = pd.read_csv(\"outputs/datasets/datacollection/HousePrices.csv\")\n",
    "\n",
    "print(df.shape)\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "### Data Cleaning\n",
    "from feature_engine.imputation import ArbitraryNumberImputer\n",
    "from feature_engine.imputation import CategoricalImputer\n",
    "from feature_engine.imputation import MeanMedianImputer\n",
    "\n",
    "### Feature Engineering\n",
    "from feature_engine import transformation as vt\n",
    "from feature_engine.outliers import Winsorizer\n",
    "from feature_engine.encoding import OrdinalEncoder\n",
    "from feature_engine.selection import SmartCorrelatedSelection\n",
    "\n",
    "### Feature Scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "### Feature Selection \n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "### ML algorithms\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor, RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "\n",
    "\n",
    "\n",
    "def PipelineOptimization(model):\n",
    "  pipeline_base = Pipeline([\n",
    "\n",
    "    ### Data Cleaning \n",
    "    \n",
    "    (\"ArbitraryNumberImputer\",ArbitraryNumberImputer(arbitrary_number=0,\n",
    "                                variables = ['2ndFlrSF', 'EnclosedPorch', 'MasVnrArea', 'WoodDeckSF']) ),\n",
    "\n",
    "    (\"CategoricalEncoder\",CategoricalImputer(imputation_method='missing',fill_value='Unf',\n",
    "                                variables = ['BsmtFinType1', 'GarageFinish'])),\n",
    "\n",
    "    (\"MeanMedianImputer\",MeanMedianImputer(imputation_method='median', \n",
    "                                variables = ['BedroomAbvGr', 'GarageYrBlt', 'LotFrontage']) ),  \n",
    "    ### Feature Engineering \n",
    "    (\"Ordinalencoder\", OrdinalEncoder(encoding_method='arbitrary', \n",
    "                          variables = [\"GarageFinish\", \"KitchenQual\", \"BsmtExposure\", \"BsmtFinType1\"]) ),\n",
    "                          \n",
    "    (\"LogTransformer\", vt.LogTransformer(\n",
    "                         variables = ['1stFlrSF', 'GrLivArea', 'LotArea', 'LotFrontage']) ),\n",
    "\n",
    "    (\"PowerTransformer\", vt.PowerTransformer(\n",
    "                         variables = ['BsmtFinSF1', 'BsmtUnfSF', 'GarageArea', 'GrLivArea', 'MasVnrArea', 'OpenPorchSF' ]) ),\n",
    "      \n",
    "    (\"SmartCorrelatedSelection\",SmartCorrelatedSelection(variables=None, method=\"spearman\", \n",
    "                                                        threshold=0.8, selection_method=\"variance\") ),\n",
    "    (\"feat_scaling\",StandardScaler() ),\n",
    "\n",
    "    (\"feat_selection\",SelectFromModel(model) ),\n",
    "\n",
    "    (\"model\",model ),  \n",
    "     ])\n",
    "\n",
    "  return pipeline_base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "class HyperparameterOptimizationSearch:\n",
    "\n",
    "    def __init__(self, models, params):\n",
    "        self.models = models\n",
    "        self.params = params\n",
    "        self.keys = models.keys()\n",
    "        self.grid_searches = {}\n",
    "\n",
    "    def fit(self, X, y, cv, n_jobs, verbose=1, scoring=None, refit=False):\n",
    "        for key in self.keys:\n",
    "            print(f\"\\nRunning GridSearchCV for {key} \\n\")\n",
    "\n",
    "            model = PipelineOptimization(self.models[key])\n",
    "            params = self.params[key]\n",
    "            gs = GridSearchCV(model, params, cv=cv, n_jobs=n_jobs,\n",
    "                              verbose=verbose, scoring=scoring, )\n",
    "            gs.fit(X, y)\n",
    "            self.grid_searches[key] = gs\n",
    "\n",
    "    def score_summary(self, sort_by='mean_score'):\n",
    "        def row(key, scores, params):\n",
    "            d = {\n",
    "                'estimator': key,\n",
    "                'min_score': min(scores),\n",
    "                'max_score': max(scores),\n",
    "                'mean_score': np.mean(scores),\n",
    "                'std_score': np.std(scores),\n",
    "            }\n",
    "            return pd.Series({**params, **d})\n",
    "\n",
    "        rows = []\n",
    "        for k in self.grid_searches:\n",
    "            params = self.grid_searches[k].cv_results_['params']\n",
    "            scores = []\n",
    "            for i in range(self.grid_searches[k].cv):\n",
    "                key = \"split{}_test_score\".format(i)\n",
    "                r = self.grid_searches[k].cv_results_[key]\n",
    "                scores.append(r.reshape(len(params), 1))\n",
    "\n",
    "            all_scores = np.hstack(scores)\n",
    "            for p, s in zip(params, all_scores):\n",
    "                rows.append((row(k, s, p)))\n",
    "\n",
    "        df = pd.concat(rows, axis=1).T.sort_values([sort_by], ascending=False)\n",
    "        columns = ['estimator', 'min_score',\n",
    "                   'mean_score', 'max_score', 'std_score']\n",
    "        columns = columns + [c for c in df.columns if c not in columns]\n",
    "        return df[columns], self.grid_searches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test,y_train, y_test = train_test_split(\n",
    "                                    df.drop(['SalePrice'],axis=1),\n",
    "                                    df['SalePrice'],\n",
    "                                    test_size = 0.2,\n",
    "                                    random_state = 0,\n",
    "                                    )\n",
    "\n",
    "print(\"* Train set:\", X_train.shape, y_train.shape, \"\\n* Test set:\",  X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary that maps model to their corresponding scikit-learn or XGBoost regression models.\n",
    "\n",
    "models_quick_search = {\n",
    "\n",
    "    # Linear Regression model. \n",
    "    \"LinearRegression\": LinearRegression(),\n",
    "\n",
    "    # Decision Tree Regressor model with a fixed random state for reproducibility. \n",
    "    \"DecisionTreeRegressor\": DecisionTreeRegressor(random_state=0),\n",
    "\n",
    "    # Which is an ensemble method using multiple decision trees.\n",
    "    \"RandomForestRegressor\": RandomForestRegressor(random_state=0),\n",
    "\n",
    "    # Another ensemble method similar to Random Forest, but with no more randomness.\n",
    "    \"ExtraTreesRegressor\": ExtraTreesRegressor(random_state=0),\n",
    "\n",
    "    # Which combines multiple weak learners to form a stronger model.\n",
    "    \"AdaBoostRegressor\": AdaBoostRegressor(random_state=0),\n",
    "\n",
    "    # Another ensemble method that builds trees sequentially to correct previous errors.\n",
    "    \"GradientBoostingRegressor\": GradientBoostingRegressor(random_state=0),\n",
    "\n",
    "    # A powerful gradient boosting framework that is often more efficient and accurate. \n",
    "    \"XGBRegressor\": XGBRegressor(random_state=0),\n",
    "}\n",
    "\n",
    "# Dictionary that maps each model name to an empty dictionary or parameters. \n",
    "# This is used to store or pass hyperparameters when tuning or training the models.\n",
    "params_quick_search = {\n",
    "    \"LinearRegression\": {},\n",
    "    \"DecisionTreeRegressor\": {},\n",
    "    \"RandomForestRegressor\": {},\n",
    "    \"ExtraTreesRegressor\": {},\n",
    "    \"AdaBoostRegressor\": {},\n",
    "    \"GradientBoostingRegressor\": {},\n",
    "    \"XGBRegressor\": {},\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search = HyperparameterOptimizationSearch(models=models_quick_search, params=params_quick_search)\n",
    "search.fit(X_train, y_train, scoring='r2', n_jobs=-1, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search_summary, grid_search_pipelines = search.score_summary(sort_by=\"mean_score\")\n",
    "grid_search_summary "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a list of models\n",
    "models_search = {\n",
    "    \"ExtraTreesRegressor\": ExtraTreesRegressor(random_state=0)\n",
    "}\n",
    "\n",
    "# Define a dictionary for parameter grids to corresponding to the model names\n",
    "params_search = {\n",
    "    \"ExtraTreesRegressor\": {\n",
    "        \"model__n_estimators\": [50, 100, 150],\n",
    "        \"model__max_depth\": [None, 3, 15],\n",
    "        \"model__min_samples_split\": [2, 50],\n",
    "        \"model__min_samples_leaf\": [1, 50]\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search = HyperparameterOptimizationSearch(models=models_search, params=params_search)\n",
    "search.fit(X_train, y_train, scoring = 'r2', n_jobs=-1, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search_summary, grid_search_pipelines = search.score_summary(sort_by=\"mean_score\")\n",
    "grid_search_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = grid_search_summary.iloc[0,0]\n",
    "best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_parameters = grid_search_pipelines[best_model].best_params_\n",
    "best_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor_pipeline = grid_search_pipelines[best_model].best_estimator_\n",
    "regressor_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "# Define the number of data cleaning and feature engineering steps\n",
    "data_cleaning_feat_eng_steps = 7 \n",
    "\n",
    "# Extract columns after data cleaning and feature engineering steps\n",
    "columns_after_cleaning = (\n",
    "    Pipeline(regressor_pipeline.steps[:data_cleaning_feat_eng_steps])\n",
    "    .transform(X_train)\n",
    "    .columns\n",
    ")\n",
    "\n",
    "# Get the list of selected features\n",
    "selected_features_mask = regressor_pipeline[\"feat_selection\"].get_support()\n",
    "best_features = columns_after_cleaning[selected_features_mask].tolist()\n",
    "\n",
    "# Create a DataFrame to display feature importance\n",
    "df_feature_importance = (\n",
    "    pd.DataFrame({\n",
    "        \"Feature\": columns_after_cleaning[selected_features_mask],\n",
    "        \"Importance\": regressor_pipeline[\"model\"].feature_importances_\n",
    "    })\n",
    "    .sort_values(by=\"Importance\", ascending=False)\n",
    ")\n",
    "\n",
    "# Print most important features\n",
    "print(\n",
    "    f\"* These are the {len(best_features)} most important features in descending order. \"\n",
    "    f\"The model was trained on them: \\n{df_feature_importance['Feature'].tolist()}\"\n",
    ")\n",
    "\n",
    "# Plot feature importance\n",
    "df_feature_importance.plot(kind=\"bar\", x=\"Feature\", y=\"Importance\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score, mean_absolute_error\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "def evaluate_regression_model(X_train, y_train, X_test, y_test, regressor):\n",
    "    \"\"\"\n",
    "    Evaluate the performance of a regression model on both training and test sets.\n",
    "    \"\"\"\n",
    "    print(\"Model Evaluation\\n\")\n",
    "    evaluate_on_dataset(X_train, y_train, regressor, dataset_name=\"Train Set\")\n",
    "    evaluate_on_dataset(X_test, y_test, regressor, dataset_name=\"Test Set\")\n",
    "\n",
    "def evaluate_on_dataset(X_train, y_train, X_test, y_test, regressor, dataset_name=\"Test Set\"):\n",
    "    \"\"\"\n",
    "    Evaluate the regression performance on a single dataset.\n",
    "    \"\"\"\n",
    "    predictions = regressor.predict(X_test)\n",
    "    r2 = r2_score(y_test, predictions).round(3)\n",
    "    mae = mean_absolute_error(y_test, predictions).round(3)\n",
    "    print(f\"* {dataset_name}\")\n",
    "    print(f'  R2 Score: {r2}')\n",
    "    print(f'  Mean Absolute Error: {mae}\\n')\n",
    "\n",
    "def plot_regression_results(X_train, y_train, X_test, y_test, model, alpha=0.5):\n",
    "    \"\"\"\n",
    "    Plot actual vs predicted values for training and test sets.\n",
    "    \"\"\"\n",
    "    pred_train = model.predict(X_train)\n",
    "    pred_test = model.predict(X_test)\n",
    "\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(12, 6))\n",
    "\n",
    "    # Train set plot\n",
    "    sns.scatterplot(x=y_train, y=pred_train, alpha=alpha, ax=axes[0])\n",
    "    sns.lineplot(x=y_train, y=y_train, color='red', ax=axes[0])\n",
    "    axes[0].set_title(\"Train Set\")\n",
    "    axes[0].set_xlabel(\"Actual\")\n",
    "    axes[0].set_ylabel(\"Predicted\")\n",
    "\n",
    "    # Test set plot\n",
    "    sns.scatterplot(x=y_test, y=pred_test, alpha=alpha, ax=axes[1])\n",
    "    sns.lineplot(x=y_test, y=y_test, color='red', ax=axes[1])\n",
    "    axes[1].set_title(\"Test Set\")\n",
    "    axes[1].set_xlabel(\"Actual\")\n",
    "    axes[1].set_ylabel(\"Predicted\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_regression_model(X_train, y_train, X_test, y_test, regressor):\n",
    "    # Evaluate regression performance\n",
    "    evaluate_on_dataset(X_train, y_train, X_test, y_test, regressor)\n",
    "\n",
    "    # Generate evaluation plots\n",
    "    plot_regression_results(X_train, y_train, X_test, y_test, regressor)\n",
    "\n",
    "# Call the combined function\n",
    "evaluate_regression_model(X_train, y_train, X_test, y_test, regressor_pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "def PipelineOptimization(model):\n",
    "  pipeline_base = Pipeline([\n",
    "\n",
    "    ### Data Cleaning \n",
    "    \n",
    "    (\"ArbitraryNumberImputer\",ArbitraryNumberImputer(arbitrary_number=0,\n",
    "                                variables = ['2ndFlrSF', 'EnclosedPorch', 'MasVnrArea', 'WoodDeckSF']) ),\n",
    "\n",
    "    (\"CategoricalEncoder\",CategoricalImputer(imputation_method='missing',fill_value='Unf',\n",
    "                                variables = ['BsmtFinType1', 'GarageFinish'])),\n",
    "\n",
    "    (\"MeanMedianImputer\",MeanMedianImputer(imputation_method='median', \n",
    "                                variables = ['BedroomAbvGr', 'GarageYrBlt', 'LotFrontage']) ),  \n",
    "    ### Feature Engineering \n",
    "    (\"Ordinalencoder\", OrdinalEncoder(encoding_method='arbitrary', \n",
    "                          variables = [\"GarageFinish\", \"KitchenQual\", \"BsmtExposure\", \"BsmtFinType1\"]) ),\n",
    "                          \n",
    "    (\"LogTransformer\", vt.LogTransformer(\n",
    "                         variables = ['1stFlrSF', 'GrLivArea', 'LotArea', 'LotFrontage']) ),\n",
    "\n",
    "    (\"PowerTransformer\", vt.PowerTransformer(\n",
    "                         variables = ['BsmtFinSF1', 'BsmtUnfSF', 'GarageArea', 'GrLivArea', 'MasVnrArea', 'OpenPorchSF' ]) ),\n",
    "      \n",
    "    (\"SmartCorrelatedSelection\",SmartCorrelatedSelection(variables=None, method=\"spearman\", \n",
    "                                                        threshold=0.8, selection_method=\"variance\") ),\n",
    "    (\"feat_scaling\",StandardScaler() ),\n",
    "\n",
    "    (\"feat_selection\",SelectFromModel(model) ),\n",
    "\n",
    "    (\"model\",model ),  \n",
    "     ])\n",
    "\n",
    "  return pipeline_base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code is being resued from above. \n",
    "\n",
    "print(\"* Train set:\", X_train.shape, y_train.shape, \"\\n* Test set:\",  X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_search = {\n",
    "    \"ExtraTreesRegressor\": {\"model__n_estimators\": [50, 100, 150],\n",
    "    \"model__max_depth\": [None, 3, 15],\n",
    "    \"model__min_samples_split\": [2, 50],\n",
    "    \"model__min_samples_leaf\": [1, 50],\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search = HyperparameterOptimizationSearch(models=models_search, params=params_search)\n",
    "search.fit(X_train, y_train, scoring = 'r2', n_jobs=-1, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search_summary, grid_search_pipelines = search.score_summary(sort_by=\"mean_score\")\n",
    "grid_search_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = grid_search_summary.iloc[0,0]\n",
    "best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_pipeline_regressor = grid_search_pipelines[best_model].best_estimator_\n",
    "best_pipeline_regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import os\n",
    "\n",
    "version = \"v1\"\n",
    "file_path = f\"outputs/ml_pipeline/predictsale_price/{version}\"\n",
    "\n",
    "try:\n",
    "    os.makedirs(name=file_path)\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.to_csv(f\"{file_path}/X_train.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.to_csv(f\"{file_path}/y_train.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.to_csv(f\"{file_path}/X_test.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test.to_csv(f\"{file_path}/y_test.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "joblib.dump(value=best_pipeline_regressor, filename=f\"{file_path}/regression_pipeline.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort the features by importance for better visualization \n",
    "df_feature_importance = df_feature_importance.sort_values(by=\"Importance\", ascending=False)\n",
    "\n",
    "# Create bar plot\n",
    "plt.bar(df_feature_importance[\"Feature\"], df_feature_importance[\"Importance\"])\n",
    "plt.xlabel(\"Feature\")\n",
    "plt.ylabel(\"Importance\")\n",
    "plt.title(\"Feature Importance\")\n",
    "plt.xticks(rotation=45, ha=\"right\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_feature_importance.plot(kind=\"bar\", x=\"Feature\", y=\"Importance\")\n",
    "plt.savefig(f\"{file_path}/features_importance.png\", bbox_inches=\"tight\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
